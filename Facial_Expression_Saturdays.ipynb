{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mB-O_VvhJXQ"
   },
   "source": [
    "# **AISaturdays ECG Challenge**\n",
    "\n",
    "![AISaturdays](https://www.saturdays.ai/assets/images/ai-saturdays-122x122.png)\n",
    "\n",
    "Bienvenidas todas las personas al reto de esta semana. Esta vez detectaremos casos de enfermedad cardiovascular a través del análisis de electrocardiogramas (ECG) de los latidos del corazón.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "- Se usará el lenguaje de programación Python 3.\n",
    "- Se usarán las librerías de python: Pandas, MatPlotLib, Numpy y keras.\n",
    "\n",
    "**Mediante este ejercicio, aprenderemos:**\n",
    "- Entender y ejecutar los NoteBooks con Python.\n",
    "- Ser capaz de utilizar funciones de Python y librerías adicionales.\n",
    "- Dataset:\n",
    " - Obtener el dataset y previsualizar la información del dataset.\n",
    " - Limpiar y normalizar la información del dataset.\n",
    " - Representar y analizar la información del dataset.\n",
    "- Aplicar un modelo de NN .\n",
    "- Mejorar la predicción optimizando el modelo.\n",
    "\n",
    "Este ejercicio está basado en un [paper](https://arxiv.org/pdf/1805.00794.pdf) que resuelve el problema al que nos enfrentamos. Tomadlo como una fuente de inspiración.\n",
    "\n",
    "¡Empecemos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ao9twkE1hJXS"
   },
   "source": [
    "### 0. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pky60QgthJXT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1jYJBHThJXU"
   },
   "source": [
    "## Análisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mujwvIabhJXU"
   },
   "source": [
    "### 1. Importa el dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5fsEI219hJXV"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código.\n",
    "df = pd.read_csv('mitbih_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PZFp_wYchJXa"
   },
   "source": [
    "### 2. ¿Qué forma tiene el dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoTfVW45hJXb",
    "outputId": "8d25202a-eaef-4684-8a99-f5ee1e984019"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87553, 188)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solo una linea de código.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pFsJVphghJXf"
   },
   "source": [
    "### 3. Vamos a ver cómo son los datos. Muestra las primero cinco filas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q39SynfYhJXg",
    "outputId": "1f938576-7582-4be6-b6ae-e2617585fd6e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9.779411554336547852e-01</th>\n",
       "      <th>9.264705777168273926e-01</th>\n",
       "      <th>6.813725233078002930e-01</th>\n",
       "      <th>2.450980395078659058e-01</th>\n",
       "      <th>1.544117629528045654e-01</th>\n",
       "      <th>1.911764740943908691e-01</th>\n",
       "      <th>1.519607901573181152e-01</th>\n",
       "      <th>8.578431606292724609e-02</th>\n",
       "      <th>5.882352963089942932e-02</th>\n",
       "      <th>4.901960864663124084e-02</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000000000000000000e+00.79</th>\n",
       "      <th>0.000000000000000000e+00.80</th>\n",
       "      <th>0.000000000000000000e+00.81</th>\n",
       "      <th>0.000000000000000000e+00.82</th>\n",
       "      <th>0.000000000000000000e+00.83</th>\n",
       "      <th>0.000000000000000000e+00.84</th>\n",
       "      <th>0.000000000000000000e+00.85</th>\n",
       "      <th>0.000000000000000000e+00.86</th>\n",
       "      <th>0.000000000000000000e+00.87</th>\n",
       "      <th>0.000000000000000000e+00.88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.967136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.356808</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.927461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.626943</td>\n",
       "      <td>0.193437</td>\n",
       "      <td>0.094991</td>\n",
       "      <td>0.072539</td>\n",
       "      <td>0.043178</td>\n",
       "      <td>0.053541</td>\n",
       "      <td>0.093264</td>\n",
       "      <td>0.189983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   9.779411554336547852e-01  9.264705777168273926e-01  \\\n",
       "0                  0.960114                  0.863248   \n",
       "1                  1.000000                  0.659459   \n",
       "2                  0.925414                  0.665746   \n",
       "3                  0.967136                  1.000000   \n",
       "4                  0.927461                  1.000000   \n",
       "\n",
       "   6.813725233078002930e-01  2.450980395078659058e-01  \\\n",
       "0                  0.461538                  0.196581   \n",
       "1                  0.186486                  0.070270   \n",
       "2                  0.541436                  0.276243   \n",
       "3                  0.830986                  0.586854   \n",
       "4                  0.626943                  0.193437   \n",
       "\n",
       "   1.544117629528045654e-01  1.911764740943908691e-01  \\\n",
       "0                  0.094017                  0.125356   \n",
       "1                  0.070270                  0.059459   \n",
       "2                  0.196133                  0.077348   \n",
       "3                  0.356808                  0.248826   \n",
       "4                  0.094991                  0.072539   \n",
       "\n",
       "   1.519607901573181152e-01  8.578431606292724609e-02  \\\n",
       "0                  0.099715                  0.088319   \n",
       "1                  0.056757                  0.043243   \n",
       "2                  0.071823                  0.060773   \n",
       "3                  0.145540                  0.089202   \n",
       "4                  0.043178                  0.053541   \n",
       "\n",
       "   5.882352963089942932e-02  4.901960864663124084e-02  ...  \\\n",
       "0                  0.074074                  0.082621  ...   \n",
       "1                  0.054054                  0.045946  ...   \n",
       "2                  0.066298                  0.058011  ...   \n",
       "3                  0.117371                  0.150235  ...   \n",
       "4                  0.093264                  0.189983  ...   \n",
       "\n",
       "   0.000000000000000000e+00.79  0.000000000000000000e+00.80  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   0.000000000000000000e+00.81  0.000000000000000000e+00.82  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   0.000000000000000000e+00.83  0.000000000000000000e+00.84  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   0.000000000000000000e+00.85  0.000000000000000000e+00.86  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   0.000000000000000000e+00.87  0.000000000000000000e+00.88  \n",
       "0                          0.0                          0.0  \n",
       "1                          0.0                          0.0  \n",
       "2                          0.0                          0.0  \n",
       "3                          0.0                          0.0  \n",
       "4                          0.0                          0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solo una linea de código.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q40at1iFhJXj"
   },
   "source": [
    "Este es el dataset de hoy. Esta vez, cada columna representa una lectura del electrocardiograma (recogido a 125Hz). Si en total hay 187 lecturas, en estas columnas tenemos alrededor de segundo y medio de pulsaciones. La última columna contiene la categoría a la que pertenecen estas pulsaciones. En total hay cinco, cada una representada por un número: \n",
    "\n",
    "- Normal: 0\n",
    "- Arritmia prematura (atrial, aberrante-atrial, nodal o supra-ventricular) : 1\n",
    "- Contracción prematura ventricular o escape ventricular: 2\n",
    "- Fusión de la contracción ventricular y normal: 3\n",
    "- Resucitación, fusión de normal y resucitación o inclasificable: 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QUcQbT7shJXk"
   },
   "source": [
    "### 4. Describe la distribución de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U28kFZeuhJXl",
    "outputId": "82ac2fc3-8cfc-4dcf-bb07-44dfdb4f1e2d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9.779411554336547852e-01</th>\n",
       "      <th>9.264705777168273926e-01</th>\n",
       "      <th>6.813725233078002930e-01</th>\n",
       "      <th>2.450980395078659058e-01</th>\n",
       "      <th>1.544117629528045654e-01</th>\n",
       "      <th>1.911764740943908691e-01</th>\n",
       "      <th>1.519607901573181152e-01</th>\n",
       "      <th>8.578431606292724609e-02</th>\n",
       "      <th>5.882352963089942932e-02</th>\n",
       "      <th>4.901960864663124084e-02</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000000000000000000e+00.79</th>\n",
       "      <th>0.000000000000000000e+00.80</th>\n",
       "      <th>0.000000000000000000e+00.81</th>\n",
       "      <th>0.000000000000000000e+00.82</th>\n",
       "      <th>0.000000000000000000e+00.83</th>\n",
       "      <th>0.000000000000000000e+00.84</th>\n",
       "      <th>0.000000000000000000e+00.85</th>\n",
       "      <th>0.000000000000000000e+00.86</th>\n",
       "      <th>0.000000000000000000e+00.87</th>\n",
       "      <th>0.000000000000000000e+00.88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "      <td>87553.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.890359</td>\n",
       "      <td>0.758158</td>\n",
       "      <td>0.423969</td>\n",
       "      <td>0.219104</td>\n",
       "      <td>0.201127</td>\n",
       "      <td>0.210399</td>\n",
       "      <td>0.205809</td>\n",
       "      <td>0.201774</td>\n",
       "      <td>0.198693</td>\n",
       "      <td>0.196758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.473382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.240910</td>\n",
       "      <td>0.221814</td>\n",
       "      <td>0.227305</td>\n",
       "      <td>0.206880</td>\n",
       "      <td>0.177058</td>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.178482</td>\n",
       "      <td>0.177241</td>\n",
       "      <td>0.171778</td>\n",
       "      <td>0.168358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044155</td>\n",
       "      <td>0.042089</td>\n",
       "      <td>0.040525</td>\n",
       "      <td>0.038651</td>\n",
       "      <td>0.037193</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>0.032865</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>1.143190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.921922</td>\n",
       "      <td>0.682482</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>0.048458</td>\n",
       "      <td>0.082329</td>\n",
       "      <td>0.088415</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.068643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.991342</td>\n",
       "      <td>0.826007</td>\n",
       "      <td>0.429467</td>\n",
       "      <td>0.165992</td>\n",
       "      <td>0.147870</td>\n",
       "      <td>0.158798</td>\n",
       "      <td>0.145320</td>\n",
       "      <td>0.144424</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.148734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910506</td>\n",
       "      <td>0.578767</td>\n",
       "      <td>0.341727</td>\n",
       "      <td>0.258993</td>\n",
       "      <td>0.287634</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.295393</td>\n",
       "      <td>0.290837</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       9.779411554336547852e-01  9.264705777168273926e-01  \\\n",
       "count              87553.000000              87553.000000   \n",
       "mean                   0.890359                  0.758158   \n",
       "std                    0.240910                  0.221814   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.921922                  0.682482   \n",
       "50%                    0.991342                  0.826007   \n",
       "75%                    1.000000                  0.910506   \n",
       "max                    1.000000                  1.000000   \n",
       "\n",
       "       6.813725233078002930e-01  2.450980395078659058e-01  \\\n",
       "count              87553.000000              87553.000000   \n",
       "mean                   0.423969                  0.219104   \n",
       "std                    0.227305                  0.206880   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.250965                  0.048458   \n",
       "50%                    0.429467                  0.165992   \n",
       "75%                    0.578767                  0.341727   \n",
       "max                    1.000000                  1.000000   \n",
       "\n",
       "       1.544117629528045654e-01  1.911764740943908691e-01  \\\n",
       "count              87553.000000              87553.000000   \n",
       "mean                   0.201127                  0.210399   \n",
       "std                    0.177058                  0.171910   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.082329                  0.088415   \n",
       "50%                    0.147870                  0.158798   \n",
       "75%                    0.258993                  0.287634   \n",
       "max                    1.000000                  1.000000   \n",
       "\n",
       "       1.519607901573181152e-01  8.578431606292724609e-02  \\\n",
       "count              87553.000000              87553.000000   \n",
       "mean                   0.205809                  0.201774   \n",
       "std                    0.178482                  0.177241   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.073333                  0.066116   \n",
       "50%                    0.145320                  0.144424   \n",
       "75%                    0.298246                  0.295393   \n",
       "max                    1.000000                  1.000000   \n",
       "\n",
       "       5.882352963089942932e-02  4.901960864663124084e-02  ...  \\\n",
       "count              87553.000000              87553.000000  ...   \n",
       "mean                   0.198693                  0.196758  ...   \n",
       "std                    0.171778                  0.168358  ...   \n",
       "min                    0.000000                  0.000000  ...   \n",
       "25%                    0.065000                  0.068643  ...   \n",
       "50%                    0.150000                  0.148734  ...   \n",
       "75%                    0.290837                  0.283636  ...   \n",
       "max                    1.000000                  1.000000  ...   \n",
       "\n",
       "       0.000000000000000000e+00.79  0.000000000000000000e+00.80  \\\n",
       "count                 87553.000000                 87553.000000   \n",
       "mean                      0.005025                     0.004628   \n",
       "std                       0.044155                     0.042089   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.000000                     0.000000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       0.000000000000000000e+00.81  0.000000000000000000e+00.82  \\\n",
       "count                 87553.000000                 87553.000000   \n",
       "mean                      0.004291                     0.003945   \n",
       "std                       0.040525                     0.038651   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.000000                     0.000000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       0.000000000000000000e+00.83  0.000000000000000000e+00.84  \\\n",
       "count                 87553.000000                 87553.000000   \n",
       "mean                      0.003681                     0.003471   \n",
       "std                       0.037193                     0.036255   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.000000                     0.000000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       0.000000000000000000e+00.85  0.000000000000000000e+00.86  \\\n",
       "count                 87553.000000                 87553.000000   \n",
       "mean                      0.003221                     0.002945   \n",
       "std                       0.034790                     0.032865   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.000000                     0.000000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       0.000000000000000000e+00.87  0.000000000000000000e+00.88  \n",
       "count                 87553.000000                 87553.000000  \n",
       "mean                      0.002807                     0.473382  \n",
       "std                       0.031924                     1.143190  \n",
       "min                       0.000000                     0.000000  \n",
       "25%                       0.000000                     0.000000  \n",
       "50%                       0.000000                     0.000000  \n",
       "75%                       0.000000                     0.000000  \n",
       "max                       1.000000                     4.000000  \n",
       "\n",
       "[8 rows x 188 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solo una linea de código.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L2kz9b1jhJXo"
   },
   "source": [
    "### 5. Vamos a ver cómo es uno de estos electrocardiogramas. Haz una gráfica con los datos de una de las filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50XGDJS5hJXp",
    "outputId": "722340f3-5829-4b6c-ec44-b3fd9a3e4b13",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Solo una linea de código.\n",
    "df.iloc[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGRsUDc_hJXt"
   },
   "source": [
    "### 6. Ahora que hemos visualizado nuestros datos, vamos a trabajar con ellos. Primero tenemos que dividirlos entre input y output. \n",
    "\n",
    "Divide el dataset en dos: una parte que contenga todas las columnas con datos del electrocardiograma y otro con las etiquetas. Transformar el dataset en un array de Numpy lo hace mas fácil porque puedes usar slicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfVdyFcfhJXu"
   },
   "outputs": [],
   "source": [
    "#Tres lineas de código, usando .values y slicing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YloJfZUhJXw"
   },
   "source": [
    "### 7. Crea arrays con los índices de los ejemplos que pertenecen a cada categoría. La función [np.argwhere](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argwhere.html) viene muy bien aquí. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Be68Gpi2hJXx"
   },
   "outputs": [],
   "source": [
    "#5 lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8DFkW8bhJX0"
   },
   "source": [
    "### 8. Cuenta cuántos ejemplos tenemos de cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lvyQIIBhJX0",
    "outputId": "10274d37-df9b-4ca0-bf58-429ccff39318",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#5 lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBlbXOgBhJX3"
   },
   "source": [
    "### 9. Para ver mejor cuántos tenemos de cada tipo vamos a hacer un gráfico de barras. Utiliza [plt.bar](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.bar.html) con una label apropiada para cada barra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-AMnfX0hJX3",
    "outputId": "0873d997-7f4d-407a-d3b0-9d6302b984d1"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTemtlxIhJX9"
   },
   "source": [
    "### 10. Finalmente, vamos a comparar electrocardiogramas de un tipo con los otros con otra gráfica. Dibuja un electrocardiograma de cada tipo, uno encima del otro. Puntos extra por ponerle un título y leyenda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5KjUhmHhJX9"
   },
   "outputs": [],
   "source": [
    "#6 lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Id6hugrmhJYA"
   },
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fAgikAoWhJYB"
   },
   "source": [
    "### 11. La mejor forma de tratar con categorias es utilizar un OneHotEncoding. Transforma Y a su OneHotEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIDdzcpihJYB"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sSftNhMhJYD"
   },
   "source": [
    "### 12. Comprueba que el OneHotEncoding ha funcionado, es decir, que por cada columna en la Y original se han creado 5, y que los valores del original y el OneHotEncoding se corresponden entre sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xvZ_kwbhJYE",
    "outputId": "87de7a25-d38d-460b-a4be-23de53bcd09b"
   },
   "outputs": [],
   "source": [
    "#4 lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OH84gOWGhJYH"
   },
   "source": [
    "### 13. Mezcla X e Y de forma aleatoria (para que las etiquetas todavía se refieran a los ejemplos originales, usa [shuffle](https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AWwJCX7hJYH"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T721f2zthJYQ"
   },
   "source": [
    "### 14. Para poder introducir los datos en el modelo, necesitamos que cada punto de información esté solo dentro del array (no podemos dar un array como valor). Antes teníamos los datos estructurados así:\n",
    "\n",
    "$ X = [[a_1,a_2,a_3...,a_n],[b_1,b_2,b_3...,b_n]...[z_1,z_2,z_3,z_n] $\n",
    "\n",
    "Para poder usarlos necesitamos aislar cada uno de esos valores, sin eliminar su agrupación por ejemplos. Es decir:\n",
    "\n",
    "$ X = [[[a_1],[a_2],[a_3]...,[a_n]],[[b_1],[b_2],[b_3]...,[b_n]]...[[z_1],[z_2],[z_3],[z_n]] $\n",
    "\n",
    "Esto se consigue utilizando la función [expand_dims](https://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html) de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITtKUKQhhJYR"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-giOiqiYhJYT"
   },
   "source": [
    "### 15. ¡Ya casi estamos! Solo nos queda hacer un train_test_split y estaría todo listo para implementar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "js6uqn4BhJYU"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2OXup6RhJYW"
   },
   "source": [
    "## Modelos prometedores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ye1mPrYohJYW"
   },
   "source": [
    "En esta parte del challenge os planteamos un modelo ya creado para que podais ver como funciona y trastear con los diferentes parámetros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHGzAc55hJYX"
   },
   "source": [
    "Primero importamos unas pocas librerias para plantear el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7zqDfcAhJYX"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6cd3af4470a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras import models, layers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nC6AHHMvhJYZ"
   },
   "source": [
    "### 16. ¿Cuál es la longitud de la entrada? (Esta será la cantidad de neuronas que tendremos en la primera capa).¿Cuántas neuronas tendremos en nuestra última capa? También necesitamos un batch_size si queremos entrenar la red neuronal con SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2t48inzhJYa"
   },
   "outputs": [],
   "source": [
    "signal_length = \n",
    "n_classes = \n",
    "batch_size = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9W8F-CVJhJYd"
   },
   "source": [
    "Este es el modelo de la red neuronal. Tiene cuatro capas, dos de ellas ocultas, y utiliza como función de activación ReLU, sigmoid y softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBc_yhfThJYe",
    "outputId": "b60eb195-6c94-4a41-d75a-a00e94971fe7"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=(5), input_shape=(signal_length, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv1D(32, (4)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(32, (4)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(32, (4)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GdhXK-U1hJYg"
   },
   "source": [
    "Para compilar el modelo, se llama .compile(). Aquí se especifica que función de pérdida usamos, que optimizadores aplicamos y que métricas queremos guardar de cada epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CB5NPusjhJYg"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFrpp2yShJYi"
   },
   "source": [
    "Ahora entrenamos el modelo un número de épocas y con una batch_size especifica. Esto nos devuelve un objeto history con la accuracy de todas las fases de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mf7fDdchJYi",
    "outputId": "6656fc56-133a-4a48-bd49-77efaa251f63"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=75, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NliUnXSGhJYl"
   },
   "source": [
    "### 17. Accede a la accuracy histórica del modelo (con el atributo history)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWds4b6ChJYl",
    "outputId": "a4255044-3b63-4b4d-adea-08a65c5da792"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzB3t9CYhJYo"
   },
   "source": [
    "### 18. Ahora podemos ver si nuestro modelo está haciendo overfitting. Dibuja una gráfica con la accuracy en train y en validation usando los datos del objeto history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KP_SRAnphJYp",
    "outputId": "43c5e9ba-51c1-4adc-aaa2-fe1e4825d40b"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2RC2_pghJYr"
   },
   "source": [
    "### 19. Lo mismo, pero con la pérdida o loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaJxqJWYhJYs",
    "outputId": "b320b106-1c86-4e5b-d9d4-a6f186e54b4b"
   },
   "outputs": [],
   "source": [
    "#Dos lineas de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFu3wMNZhJYv"
   },
   "source": [
    "### 20. Vamos a ver lo que predice con el X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vd1FIayQhJYw"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YVhxvfzLhJYy"
   },
   "source": [
    "### 21. ¿Qué dimensiones tiene la predicción y_pred?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6M4DrqzZhJYz",
    "outputId": "4fd63c75-7e76-4c07-e2be-29f6f5217ad6"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BBuCsReShJY2"
   },
   "source": [
    "### 22. Compara una predicción con el valor esperado utilizando un gráfico de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGsxbYnWhJY3",
    "outputId": "61943267-f1d2-42c8-d9e3-2a57ee8de15e"
   },
   "outputs": [],
   "source": [
    "#Solo una linea de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXFer3AZhJY5"
   },
   "source": [
    "¿El modelo plantea una sola posibilidad o las probabilidades de cada categoria al estimar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoQVwwFhhJY5"
   },
   "source": [
    "Este snippet de código genera un report del modelo, y el siguiente una matriz de confusión. Utilizadlo para evaluar vuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YX_k97bghJY6",
    "outputId": "53a2a5b0-49c7-4c98-c3e3-b1e5f225de73"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3E_a95ihJY8",
    "outputId": "77424721-254d-4556-a7b0-fa7f40a16bf9"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],\n",
    "                      title='Confusion matrix, with normalization',\n",
    "                      normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXtlz07VhJZB"
   },
   "source": [
    "**Preguntas:**\n",
    "- Si tomamos todo lo que no sea normal como positivo, ¿el modelo se equivoca mas en falsos positivos o en falsos negativos?\n",
    "- ¿Que categoría genera mayor error?\n",
    "- ¿Existe overfitting?\n",
    "- ¿Como afecta batch_size al entrenamiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6jdUQrynhJZD"
   },
   "source": [
    "Ahora os toca a vosotros mejorar el modelo. Probad con otros optimizadores, cambiar la función de coste, volveros locos con el batch_size..... El paper del principio puede dar alguna pista. Como siempre, el que tenga la mejor score, ¡tiene premio!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AISaturdays_ChallengeSession5.ipynb",
   "provenance": [
    {
     "file_id": "1eDULJv1udQFKK4WLY0M_f9jBxibhzmXs",
     "timestamp": 1583527306059
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
